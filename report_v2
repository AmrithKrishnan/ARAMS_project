## ARAMS Course Project Report

### ROS2 Files for Autonomous Driving

The ARAMS Course Project aims to implement autonomous driving capabilities for a Prius car in the virtual city environment called "Arams City." The project is developed using ROS2 (Robot Operating System 2) and involves various packages for different functionalities.

### Components and Nodes

1. **img_proc Package**

    This package contains nodes responsible for image processing tasks. It consists of the following node:

    - `crop_raw_img`: Subscribes to the `/prius/front_camera/image_raw` topic, crops the top right corner of the raw image to extract the region of interest (ROI) for traffic light detection using YOLO. It then publishes the cropped image to the topic `/traffic_light_roi`.

2. **my_robot_nav Package**

    This package contains nodes and configuration files essential for robot navigation. It consists of the following nodes:

    - `prius_cmd_vel_mirror`: Subscribes to the `/cmd_vel` topic, which is the output topic from nav2 for navigation, and mirrors the velocity values to `/prius/cmd_vel`. This node is primarily for debugging and testing purposes with the nav2 stack.

    - `prius_cmd_vel_traffic_light`: Based on the color status received from the `traffic_light_detect` node, it controls the velocity published on the `/prius/cmd_vel` topic. When the traffic light is red, the car stops; for a yellow light, it reduces speed; and for a green light, it moves forward.

    - `auto_explorer`: Generates and sends three random navigation goals to the Prius car, allowing it to navigate autonomously to these positions in sequence. The goals are based on a fixed set of 12 predefined coordinates.

    Additionally, the `my_robot_nav` package includes configuration and launch files:

    - `nav2_params.yaml`: Contains navigation parameters for the navigation stack.
    - `localization.launch.yaml`: Launch file for localization related configurations.
    - `navigation_launch.py`: Launch file for the navigation server.
    - `robot_nav.launch.py`: Main launch file for navigation, linking `navigation_launch.py` and the `nav2_params.yaml` file.

    Moreover, two map files are included:

    - `my_map.pgm` and `my_map.yaml`: Map files for the primary navigation environment.
    - `my_map1.pgm` and `my_map1.yaml`: Alternate map files for testing and comparison.

3. **yolo Package**

    This package contains the `yolo_node`, which is a vital component for traffic light and truck detection using the YOLOv4 (You Only Look Once) pre-trained neural network. The node subscribes to the `/traffic_light_roi` topic to receive cropped images from the `img_proc` package. It uses the YOLOv4 model to detect traffic lights and trucks and publishes the cropped traffic light images to the `/traffic_light_cropped` topic. Additionally, if a truck is detected, it publishes a message "1" to the `/truck_status` topic.

### Files

1. **crop_raw_img**

The `crop_raw_img` node is responsible for processing raw images captured from the front camera mounted on the Prius car. It subscribes to the `/prius/front_camera/image_raw` topic and crops the top right corner of the raw image, extracting the region of interest (ROI) required for traffic light detection using YOLO (You Only Look Once). The cropped image is then published to the `/traffic_light_roi` topic.

2. **prius_cmd_vel_mirror**

The `prius_cmd_vel_mirror` node plays a crucial role in debugging and testing the navigation stack. It subscribes to the `/cmd_vel` topic, which is the output topic from nav2 for navigation. This node mirrors the velocity values received on `/cmd_vel` and publishes them to the `/prius/cmd_vel` topic. This allows monitoring and analyzing the velocity commands sent by the navigation stack before integration with the Prius car's actual control system.

3. **prius_cmd_vel_traffic_light**

The `prius_cmd_vel_traffic_light` node is responsible for controlling the Prius car's velocity based on the detected traffic light color. It subscribes to the `/status_message` topic to receive the color status information from the `traffic_light_detect` node. Depending on the traffic light color (red, yellow, or green), the node sets the appropriate velocity values for the car, allowing it to respond to traffic signals autonomously.

4. **auto_explorer**

The `auto_explorer` node generates random navigation goals and sends them to the Prius car. It is designed for fully autonomous navigation, allowing the car to navigate to these random positions in sequence. The node selects the navigation goals from a predefined set of 12 coordinates, ensuring that the car explores different areas of the virtual city environment.

5. **traffic_light_detection**

The `traffic_light_detection` node is a vital component responsible for detecting the color of traffic lights in the images received from the YOLO node. It subscribes to the `/traffic_light_cropped` topic, which contains cropped images of traffic lights captured from the front camera. The node processes these images using image processing techniques to determine the color of the traffic light. After analyzing the images, it sends the color status over the `/status_message` topic. Additionally, the processed image is published to the `/output_opencv` topic, enabling visualization of the detection results on Rviz.

6. **yolo_node**

The `yolo_node` is a crucial component for traffic light and truck detection in the virtual city environment. It utilizes the YOLOv4 (You Only Look Once) pre-trained neural network to detect traffic lights and trucks in the received images. The node subscribes to the `/traffic_light_roi` topic to receive cropped images from the `img_proc` package. After processing the images with YOLOv4, it publishes the cropped traffic light images to the `/traffic_light_cropped` topic. Moreover, if the YOLO model detects a truck, the node publishes a message "1" to the `/truck_status` topic.

### Config and Launch Files

1. **nav2_params.yaml**

The `nav2_params.yaml` file contains essential navigation parameters for the ROS Navigation Stack (Nav2). These parameters define various settings related to the robot's behavior, such as planner configurations, costmaps, and recovery behaviors. By modifying these parameters, the behavior and performance of the robot's navigation system can be fine-tuned to suit the specific environment and requirements.

2. **localization.launch.yaml**

The `localization.launch.yaml` file is a launch file used to configure the localization system for the Prius car. It includes the parameters and settings required to perform localization using sensor data such as odometry, IMU, and GPS, if available. Proper localization is essential for the robot to accurately determine its position within the environment and navigate effectively.

3. **navigation_launch.py**

The `navigation_launch.py` file is a launch file used to start the navigation server in the ROS Navigation Stack (Nav2). It loads the necessary plugins, configurations, and other components required for autonomous navigation. The navigation server is a crucial component that plans and executes the robot's path to reach its desired navigation goals.

4. **robot_nav.launch.py**

The `robot_nav.launch.py` file is a launch file that orchestrates the launch of various nodes and configuration files required for the Prius car's autonomous navigation. It includes the `navigation_launch.py` file and links it with the `nav2_params.yaml` file to ensure the navigation system operates with the specified parameters.

5. **my_map.pgm and my_map.yaml**

The `my_map.pgm` and `my_map.yaml` files are the map files used for navigation. They represent the occupancy grid map of the virtual city environment in which the Prius car operates. The `my_map.yaml` file contains metadata about the map, such as resolution, origin, and dimensions, while the `my_map.pgm` file stores the actual binary data of the map.

6. **my_map1.pgm and my_map1.yaml**

The `my_map1.pgm` and `my_map1.yaml` files are alternate map files used as backups. Similar to the `my_map.pgm` and `my_map.yaml` files, they represent alternative occupancy grid maps of the virtual city environment.
